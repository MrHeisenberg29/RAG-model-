from pypdf import PdfReader
import re
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langchain_ollama import OllamaLLM


# 1Ô∏è‚É£ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–±–∑–∞—Ü–µ–≤
def extract_paragraphs(pdf_path):
    # –ß—Ç–µ–Ω–∏–µ PDF
    reader = PdfReader(pdf_path)
    text = "\n".join(page.extract_text() for page in reader.pages if page.extract_text())

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∞–±–∑–∞—Ü—ã –ø–æ –¥–≤–æ–π–Ω–æ–º—É –ø–µ—Ä–µ–Ω–æ—Å—É —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ —Ç–æ—á–∫–µ —Å –¥–≤—É–º—è –Ω–æ–≤—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
    paragraphs = re.split(r"(\n\s*\n|\.\s*\n\s*\n)", text)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞, –∏–≥–Ω–æ—Ä–∏—Ä—É—è –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –Ω–µ–Ω—É–∂–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
    paragraphs = [p.strip() for p in paragraphs if p.strip() and len(p.strip()) > 20]

    return paragraphs


# 2Ô∏è‚É£ –ó–∞–≥—Ä—É–∂–∞–µ–º PDF –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∞–±–∑–∞—Ü—ã
pdf_path = "doc1.pdf"
paragraphs = extract_paragraphs(pdf_path)
print(paragraphs)

# 3Ô∏è‚É£ –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞)
embedding_model = OllamaEmbeddings(model="deepseek-r1")
documents = [Document(page_content=p, metadata={"source": f"Paragraph {i + 1}"}) for i, p in enumerate(paragraphs)]

# –°–æ–∑–¥–∞—ë–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ FAISS
vector_db = FAISS.from_documents(documents, embedding_model)


# 4Ô∏è‚É£ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
def find_relevant_paragraphs(query, top_k=3):
    docs = vector_db.similarity_search(query, k=top_k)
    return "\n\n".join([doc.page_content for doc in docs])

context=find_relevant_paragraphs("–ß—Ç–æ —Ç–∞–∫–æ–µ –∞–±–æ–Ω–µ–Ω—Ç—Å–∫–∏–π –Ω–æ–º–µ—Ä?")
print("–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞:\n", context)
# 5Ô∏è‚É£ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏ Ollama
def query_ollama(query):
    context = find_relevant_paragraphs(query)
    print("–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞:\n", context)

    full_prompt = f"–í–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –æ—Ç–≤–µ—á–∞–π –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ —ç—Ç–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É:\n\n{context}\n\n–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–∞–∫ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ: {query}"

    llm = OllamaLLM(model="deepseek-r1")  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞
    response = llm.invoke(full_prompt)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ invoke()

    return response


# 6Ô∏è‚É£ –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞
user_query = "–ß—Ç–æ —Ç–∞–∫–æ–µ –ê–±–æ–Ω–µ–Ω—Ç—Å–∫–∏–π –Ω–æ–º–µ—Ä?"
response = query_ollama(user_query)
print("\nüí° –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:", response)
